import streamlit as st
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from data.simulation import generate_training_history

def display_training_history_tab(model_type, key_suffix=""):
    """
    Muestra el historial de entrenamiento para un modelo espec√≠fico
    
    Args:
        model_type: Tipo de modelo ('lstm', 'gru', o 'dense')
        key_suffix: Sufijo para las claves de los componentes de Streamlit
    """
    # T√≠tulo seg√∫n el modelo
    title_map = {
        'lstm': "LSTM", 
        'gru': "GRU", 
        'dense': "Red Densa"
    }
    
    # Obtener datos de entrenamiento
    history_data = generate_training_history(
        epochs=100 if model_type != 'dense' else 80, 
        model_type=model_type
    )
    
    st.markdown(f"<h3 style='text-align:center; color:#4b6cb7;'>Evoluci√≥n del Entrenamiento - {title_map.get(model_type, model_type)}</h3>", 
                unsafe_allow_html=True)
    
    # Selector de m√©tricas para visualizar
    metrics = st.multiselect(
        "Selecciona m√©tricas a visualizar:", 
        ["Loss (MSE)", "MAE"], 
        default=["Loss (MSE)"],
        key=f"{model_type}_metrics{key_suffix}"
    )
    
    # Crear figura interactiva con Plotly
    fig = make_subplots(rows=1, cols=1)
    
    # A√±adir trazos seg√∫n m√©tricas seleccionadas
    if "Loss (MSE)" in metrics:
        fig.add_trace(
            go.Scatter(x=history_data['epochs'], y=history_data['loss'], 
                       mode='lines', name='Train Loss',
                       line=dict(color='#4b6cb7', width=2))
        )
        fig.add_trace(
            go.Scatter(x=history_data['epochs'], y=history_data['val_loss'], 
                       mode='lines', name='Validation Loss',
                       line=dict(color='#4b6cb7', width=2, dash='dash'))
        )
    
    if "MAE" in metrics:
        fig.add_trace(
            go.Scatter(x=history_data['epochs'], y=history_data['mae'], 
                       mode='lines', name='Train MAE',
                       line=dict(color='#ff7043', width=2))
        )
        fig.add_trace(
            go.Scatter(x=history_data['epochs'], y=history_data['val_mae'], 
                       mode='lines', name='Validation MAE',
                       line=dict(color='#ff7043', width=2, dash='dash'))
        )
    
    # Configuraci√≥n del dise√±o
    fig.update_layout(
        title='Evoluci√≥n de m√©tricas durante el entrenamiento',
        xaxis_title='√âpocas',
        yaxis_title='Valor',
        legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1),
        height=500,
        hovermode='x unified',
        plot_bgcolor='rgba(240,242,246,0.8)'
    )
    
    # Mostrar gr√°fico
    st.plotly_chart(fig, use_container_width=True)
    
    # Informaci√≥n adicional
    with st.expander("üí° Interpretaci√≥n de resultados"):
        interpretations = {
            'lstm': """
                **An√°lisis del entrenamiento LSTM:**
                - El modelo converge alrededor de la √©poca 40, alcanzando un MSE de entrenamiento de ~0.015
                - Se observa una ligera diferencia entre las p√©rdidas de entrenamiento y validaci√≥n, indicando un buen balance sin sobreajuste significativo
                - El early stopping probablemente se activ√≥ cerca de la √©poca 60, cuando la mejora en validaci√≥n se estanc√≥
                - El modelo final tiene un MSE de 0.0132 y MAE de 0.0872 en el conjunto de prueba
            """,
            'gru': """
                **An√°lisis del entrenamiento GRU:**
                - El modelo converge m√°s lentamente que el LSTM, estabiliz√°ndose cerca de la √©poca 50
                - Muestra un MSE ligeramente superior al LSTM tanto en entrenamiento como en validaci√≥n
                - La diferencia entre entrenamiento y validaci√≥n es comparable al LSTM, sugiriendo similar capacidad de generalizaci√≥n
                - El modelo final tiene un MSE de 0.0158 y MAE de 0.0914 en el conjunto de prueba
            """,
            'dense': """
                **An√°lisis del entrenamiento Red Densa:**
                - El modelo tiene m√°s dificultades para converger, con un MSE final notablemente m√°s alto que los modelos recurrentes
                - Muestra m√°s variabilidad en las curvas, indicando menor estabilidad durante el entrenamiento
                - La diferencia entre p√©rdidas de entrenamiento y validaci√≥n es mayor, sugiriendo una menor capacidad de generalizaci√≥n
                - El modelo final tiene un MSE de 0.0283 y MAE de 0.1247 en el conjunto de prueba
            """
        }
        st.markdown(interpretations.get(model_type, ""))

def display_training_history_section():
    """Muestra la secci√≥n completa de historiales de entrenamiento con pesta√±as"""
    # Crear pesta√±as para cada modelo
    model_tabs = st.tabs(["Modelo LSTM", "Modelo GRU", "Modelo Denso"])
    
    with model_tabs[0]:  # LSTM
        display_training_history_tab('lstm')
    
    with model_tabs[1]:  # GRU
        display_training_history_tab('gru')
    
    with model_tabs[2]:  # Denso
        display_training_history_tab('dense')